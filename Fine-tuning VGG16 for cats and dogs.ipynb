{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 123s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import the VGG16 model\n",
    "\n",
    "vgg16_model = tf.keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up data paths\n",
    "\n",
    "train_path = '../Cats and Dogs/PetImages/train/train'\n",
    "valid_path = '../Cats and Dogs/PetImages/train/valid'\n",
    "test_path = '../Cats and Dogs/PetImages/train/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# create batches\n",
    "\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=train_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=10)\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=valid_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=10)\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    "    .flow_from_directory(directory=test_path, target_size=(224,224), classes=['cat', 'dog'], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert VGG16 model to a sequential model\n",
    "# leaving out the output layer - the current output is 1,000\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the model is pre-trained we'll freeze all the layers as non-trainable\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the new output layer with only 2 nodes for cat and dog\n",
    "\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# looking at the summary we now see it has an output layer with 2 nodes\n",
    "# and only 8194 trainable parameters\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 - 232s - loss: 0.3721 - accuracy: 0.8420 - val_loss: 0.2232 - val_accuracy: 0.9250\n",
      "Epoch 2/5\n",
      "100/100 - 233s - loss: 0.0903 - accuracy: 0.9640 - val_loss: 0.1659 - val_accuracy: 0.9450\n",
      "Epoch 3/5\n",
      "100/100 - 237s - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.1445 - val_accuracy: 0.9500\n",
      "Epoch 4/5\n",
      "100/100 - 269s - loss: 0.0420 - accuracy: 0.9880 - val_loss: 0.1356 - val_accuracy: 0.9500\n",
      "Epoch 5/5\n",
      "100/100 - 231s - loss: 0.0327 - accuracy: 0.9920 - val_loss: 0.1200 - val_accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ba78d09688>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "\n",
    "model.fit(x=train_batches, steps_per_epoch=len(train_batches), \n",
    "          validation_data=valid_batches, validation_steps=len(valid_batches),\n",
    "          epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see on the training set the accuracy is 99% and the loss is 0.03 which are both solid numbers. Even better is the validation set is close to those numbers with 96% accuracy and 0.12 loss. This means our model is not overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our model to make predictions on the test data\n",
    "\n",
    "predictions = model.predict(x=test_batches, steps=len(test_batches), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to print and plot the confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                         normalize=False,\n",
    "                         title='Confusion Matrix',\n",
    "                         cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "    else:\n",
    "        print('Confusion Matrix w/o Normalization')\n",
    "    print(cm)    \n",
    "    \n",
    "    thresh = cm.max()/2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix w/o Normalization\n",
      "[[48  2]\n",
      " [ 1 49]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a confusion matrix to visualize the predicitons\n",
    "\n",
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions, axis=-1))\n",
    "cm_plot_labels = ['cat','dog']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 100 images the model only predicted 3 incorrectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
